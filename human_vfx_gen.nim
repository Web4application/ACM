import std/[os, osproc, base64, json, httpclient, asyncdispatch, random, strutils]
import pixie

randomize()

const API_KEY = "YOUR_GEMINI_API_KEY" # âš ï¸ Replace with your real key
const BASE_URL = "https://generativelanguage.googleapis.com"

# --- 1. MOTION & METADATA PROBING ---

proc getMotionAndSpecs(path: string): string =
  let cmd = "ffmpeg -i " & path & " -vf \"mestimate,metadata=mode=print\" -f null - 2>&1 | grep 'avg_motion' || echo '5.0'"
  let (output, _) = execCmdEx(cmd)
  let val = if output.contains("="): output.split('=')[1].strip().parseFloat() else: 5.0
  
  if val > 12.0: result = "heavy motion blur, 1/48 shutter"
  else: result = "natural cinematic blur, 180-degree shutter"

# --- 2. THE VFX SUPER-PROCESSOR ---

proc applyHumanRealism(imagePath: string): (string, string) =
  var img = decodeImage(readFile(imagePath))
  var output = newImage(img.width, img.height)
  
  # Sample Eye Color (Center-ish)
  let p = img.getPixel(img.width div 2, img.height div 2)
  let eyeHex = "hex-" & p.r.toHex(2) & p.g.toHex(2) & p.b.toHex(2)

  for y in 0 ..< img.height:
    for x in 0 ..< img.width:
      # A. Chromatic Aberration & Grain
      let r = img.getPixel(clamp(x - 3, 0, img.width - 1), y).r
      let g = img.getPixel(x, y).g
      let b = img.getPixel(clamp(x + 3, 0, img.width - 1), y).b
      
      # B. Neural Noise Injection (Realism Secret)
      let noise = rand(-8..8).int
      let finalR = clamp(r.int + noise, 0, 255).uint8
      let finalG = clamp(g.int + noise, 0, 255).uint8
      let finalB = clamp(b.int + noise, 0, 255).uint8
      
      output.setPixel(x, y, rgba(finalR, finalG, finalB, 255))

  return (encode(output.encodePng()), eyeHex)

# --- 3. MAIN PIPELINE ---

proc generateIndistinguishableVideo(videoFile: string) {.async.} =
  echo "ðŸš€ Analyzing " & videoFile & " for Human Realism..."
  
  # Step A: Smart Scene Extraction
  let tmpRef = "raw_ref.png"
  discard execCmdEx("ffmpeg -y -i " & videoFile & " -vf \"select='gt(scene,0.4)',scale=1080:1080:force_original_aspect_ratio=increase,crop=1080:1080\" -frames:v 1 " & tmpRef)
  
  # Step B: VFX & Metadata
  let motionBlur = getMotionAndSpecs(videoFile)
  let (vfxBase64, eyeColor) = applyHumanRealism(tmpRef)
  
  # Step C: Construct the "Indistinguishable" Prompt
  let prompt = "A first-of-its-kind human cinematic shot. 4k resolution, " & motionBlur & ". " &
               "Subject has " & eyeColor & " eyes, constant iris pigment, zero shimmer. " &
               "Visible skin pores, subsurface scattering, and natural micro-expressions. " &
               "Handheld 35mm film texture, asymmetrical blinking, no CGI polish."

  # Step D: Submit to Veo 3.1
  let client = newAsyncHttpClient()
  let url = BASE_URL & "/models/veo-3.1-generate-preview:generateVideos?key=" & API_KEY
  let payload = %*{
    "prompt": prompt,
    "config": {
      "referenceImages": [{"image": {"bytesBase64Encoded": vfxBase64}, "referenceType": "asset"}],
      "resolution": "1080p",
      "enhanceRealism": true
    }
  }

  let resp = await client.post(url, $payload)
  echo "âœ… Success! Operation Name: ", (await resp.body).parseJson()["name"].getStr()
  removeFile(tmpRef)

# --- START ---
if paramCount() > 0:
  waitFor generateIndistinguishableVideo(paramStr(1))
else:
  echo "Usage: ./human_vfx_gen video.mp4"
